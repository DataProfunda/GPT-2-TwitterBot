{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 9097,
     "status": "ok",
     "timestamp": 1682287107319,
     "user": {
      "displayName": "konstanty marczak",
      "userId": "09925184578633414249"
     },
     "user_tz": -120
    },
    "id": "UCI2fg3pDUSz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "from auth_tw import get_key\n",
    "import tweepy\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(MODEL_EPOCH=4):\n",
    "\n",
    "    models_folder = \"../trained_models\"\n",
    "\n",
    "    model_path = os.path.join(models_folder, f\"gpt2_xl_manbot_{MODEL_EPOCH}.pt\")\n",
    "\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_twq.csv', encoding=\"utf8\") as csv_file:\n",
    "            data_twq = csv.reader(csv_file, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twq = pd.read_csv('data_twq.csv',sep=';').drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_first_word(tweet):\n",
    "    return str(tweet[0].split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_words = data_twq.apply(return_first_word, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumInstances = pd.DataFrame(first_words).value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(pd.DataFrame(first_words).value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propability = pd.DataFrame(pd.DataFrame(first_words).value_counts().values / sumInstances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_prob = words.join(propability,how='left', lsuffix='_left')\n",
    "word_prob.columns = ['word', 'prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1682287107319,
     "user": {
      "displayName": "konstanty marczak",
      "userId": "09925184578633414249"
     },
     "user_tz": -120
    },
    "id": "bvY_tGlxDUoB"
   },
   "outputs": [],
   "source": [
    "def choose_from_top(probs, n=5):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob = top_prob / np.sum(top_prob) # Normalize\n",
    "    choice = np.random.choice(n, 1, p = top_prob)\n",
    "    token_id = ind[choice][0]\n",
    "    return int(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_on_twitter(tweet_text = \"\"):\n",
    "\n",
    "    auth = tweepy.OAuthHandler(get_key(\"api_key\"), get_key(\"api_key_secret\"))\n",
    "    auth.set_access_token(get_key(\"access_token\"), get_key(\"access_token_secret\"))\n",
    "\n",
    "    # Create a client using tweepy.Client\n",
    "    client = tweepy.Client(bearer_token=get_key(\"bearer_token\"), consumer_key=get_key(\"api_key\"), consumer_secret=get_key(\"api_key_secret\"), access_token=get_key(\"access_token\"), access_token_secret=get_key(\"access_token_secret\"))\n",
    "\n",
    "    try:\n",
    "        response = client.create_tweet(text=tweet_text)\n",
    "        tweet_id =  response.data['id']\n",
    "        print('Tweet posted successfully! Tweet ID:', tweet_id)\n",
    "    except:\n",
    "        print('Error occurred while posting the tweet:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content(random = True,start_with='',output_file='generated_content.txt', size=5, post_on_twitter = False):\n",
    "\n",
    "    output_file_path = f'{output_file}'\n",
    "\n",
    "    model.eval()\n",
    "    if os.path.exists(output_file_path):\n",
    "        os.remove(output_file_path)\n",
    "    \n",
    "    tweet_num = 0\n",
    "    with torch.no_grad():\n",
    "   \n",
    "        for tweet_idx in range(size):\n",
    "        \n",
    "            tweet_finished = False\n",
    "            first_word = ''\n",
    "            \n",
    "            if random: \n",
    "                first_word = word_prob['word'][np.random.choice(np.arange(len(word_prob)),p=word_prob['prob'])]\n",
    "            else:\n",
    "                first_word = start_with\n",
    "            cur_ids = torch.tensor(tokenizer.encode(first_word)).unsqueeze(0).to(device)\n",
    "\n",
    "            for i in range(100):\n",
    "                outputs = model(cur_ids, labels=cur_ids)\n",
    "                loss, logits = outputs[:2]\n",
    "                softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(from only one in this case) batch and the last predicted embedding\n",
    "                if i < 3:\n",
    "                    n = 20\n",
    "                else:\n",
    "                    n = 3\n",
    "                next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=n) #Randomly(from the topN probability distribution) select the next word\n",
    "                cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) # Add the last word to the running sequence\n",
    "\n",
    "                if next_token_id in tokenizer.encode('<|endoftext|>'):\n",
    "                    tweet_finished = True\n",
    "                    break\n",
    "\n",
    "            \n",
    "            if tweet_finished:\n",
    "                \n",
    "                tweet_num = tweet_num + 1\n",
    "                \n",
    "                output_list = list(cur_ids.squeeze().to('cpu').numpy())\n",
    "                output_text = tokenizer.decode(output_list)\n",
    "                if post_on_twitter:\n",
    "                    post_on_twitter(output_text)\n",
    "                print(output_text)\n",
    "\n",
    "                with open(output_file_path, 'a', encoding='utf-8') as f:\n",
    "                    f.write(f\"{output_text} \\n\\n\")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 92423,
     "status": "ok",
     "timestamp": 1682287467293,
     "user": {
      "displayName": "konstanty marczak",
      "userId": "09925184578633414249"
     },
     "user_tz": -120
    },
    "id": "RSeLQZBeDj_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corporations profit from social media.\n",
      "\n",
      "The average person has no idea what they're doing.\n",
      "\n",
      "The average person doesn't care.\n",
      "\n",
      "The average person thinks they're the best thing they're doing.\n",
      "\n",
      "The average person doesn't care.<|endoftext|>\n",
      "Help them love what you are doing.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "generate_content(output_file = 'random5_generated.txt', size=1,post_on_twitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start tweets with \"Driving\" \n",
    "generate_content(False, 'Driving ',output_file = 'Driving_generated.txt', size=50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO9MmquDaRiTqqqY1/yf8vU",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
